{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHQlcZT2i0ys"
      },
      "source": [
        "# Comparative Study of Neural Network, and CNN using the CIFAR-10 Dataset in Keras.\n",
        "\n",
        "\n",
        "\n",
        "## Goal\n",
        "\n",
        "In this homework, you will learn about the experiences of training Neural Networks using the Keras framework. Keras is a deep learning API written in Python, capable of running on top of JAX, TensorFlow, or PyTorch. It's very simple and straightforward. For further information, you can refer to the [official documentation](https://keras.io/). Additionally, here are four basic tutorial resources for learning how to use Keras.\n",
        "\n",
        "- https://www.analyticsvidhya.com/blog/2021/06/mnist-dataset-prediction-using-keras/\n",
        "- https://github.com/wxs/keras-mnist-tutorial/blob/master/MNIST%20in%20Keras.ipynb\n",
        "- https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5\n",
        "- https://keras.io/examples/vision/mnist_convnet/\n",
        "\n",
        "\n",
        "## Instruction\n",
        "\n",
        "- Submit your assignments onto **Canvas** by the due date.\n",
        "- This is an **individual** assignment. All help from others (from the web, books other than text, or people other than the TA or instructor) must be clearly acknowledged.\n",
        "- Most coding parts can be finished with about 1-6 lines of codes.\n",
        "\n",
        "\n",
        "\n",
        "## Rubric\n",
        "\n",
        "The assignment is worth 65 points in total:\n",
        "\n",
        "### Part 1: Neural Network ( 50 points)\n",
        "\n",
        "- Step 1: Design, compile, train, and evaluate a simple neural network (10 points)\n",
        "\n",
        "- Step 2: Experiment with different activation functions and evaluate their influence on model performance (10 points)\n",
        "\n",
        "- Step 3: Adjust and experiment with the number of parameters (10 points)\n",
        "\n",
        "- Step 4: Experiment with the depth and width of your neural network (10 points)\n",
        "\n",
        "- Step 5: Build an optimized neural network based on observations from previous tasks and analyze the performance (10 points).\n",
        "\n",
        "### Part 2: Convolutional neural network  ( 15 points)\n",
        "\n",
        "Use CNN to replace the vanilla neural network from Part 1 and report your findings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "ftPSeJzHhenl"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mW1Nuj75p8P"
      },
      "source": [
        "## Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYESQC1EjIyW",
        "outputId": "c18de55d-5cbf-483d-d087-f4602a145477"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((40000, 32, 32, 3), (10000, 32, 32, 3))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load CIFAR Dataset from Keras\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to binary class matrices\n",
        "num_classes = 10\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Split the full training dataset into validation dataset in 80-20 ratio\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "x_train.shape, x_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "wvTS7alnjRGI",
        "outputId": "058de181-5a4a-4b7c-c0b8-bb9996972546"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x500 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting function\n",
        "def plot_images(X, y, number_of_images=10):\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    for i in range(number_of_images):\n",
        "        plt.subplot(1, number_of_images, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(X[i], cmap=plt.cm.binary)\n",
        "    plt.show()\n",
        "\n",
        "# Call the function\n",
        "plot_images(x_train_full, y_train_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX14lObF4pgt"
      },
      "source": [
        "## Part 1: Neural Network\n",
        "### Step 1: Build a simple neural network\n",
        "First, build a simple neural network for the CIFAR-10 dataset. You will need to:\n",
        "\n",
        "Load the CIFAR-10 dataset from Keras. Normalize the data and transform the labels to a categorical format.\n",
        "Define that simple neural network. This network should have at least **three** hidden layer using 'relu' activation and a softmax output layer for the 10 classes of the CIFAR-10 dataset.\n",
        "Compile the model. Use 'categorical_crossentropy' for your loss function and 'adam' as the optimizer. The metrics will be 'accuracy'.\n",
        "Train the model. Use a validation split of 0.2. Train for 10 epochs.\n",
        "Evaluate the model on the test set and report its accuracy.\n",
        "\n",
        "### Step 2: Change the activation\n",
        "Next, experiment with different activation functions. Repeat the Step 1 process three times-- once with 'relu' replaced with 'sigmoid', once with 'tanh', and finally with 'gelu'. For each, evaluate the model's performance and document any changes you observe.\n",
        "\n",
        "### Step 3: Change the number of parameters\n",
        "Now, significantly **increase** and **decrease** the number of parameters in your neural network (by an order of magnitude) and compare results. Observe and document how the number of network parameters influences the model's performance.\n",
        "\n",
        "### Step 4: Change the depth and width\n",
        "Now, experiment with the structure of your neural network, specifically its depth and width, and compare results while trying to keep the number of parameters fixed.\n",
        "\n",
        "***Increasing the depth***: Add more layers to your network. Try to make your model deeper by adding more layers of neurons. Keep note of how this affects training and performance.\n",
        "\n",
        "***Increasing the width***: Make your model wider by increasing the number of neurons in the hidden layers. Observe and document how this influences the model's performance.\n",
        "\n",
        "Remember that you are trying to keep the total number of parameters roughly equivalent for each alteration. This means that if you add more layers (increasing depth), you may need to reduce the number of neurons in each layer (decreasing width) to compensate, and vice versa. The aim is to explore the trade-off between network depth and width.\n",
        "\n",
        "Make sure to evaluate each alteration and compare it to the performance of your original network.\n",
        "\n",
        "### Step 5: Building an Optimized Neural Network\n",
        "Guided by your observations and findings from previous steps, it's now time to build an optimized neural network. Here are the tasks for this step:\n",
        "\n",
        "Design the Network: Based on your previous experiments, devise a network architecture that you believe will yield the best performance. Consider the number of layers, the number of neurons in each layer, and the activation functions.\n",
        "\n",
        "Compile the Model: Compile your model with the 'adam' optimizer and 'categorical_crossentropy' as the loss function. Use 'accuracy' as the evaluation metric as used previously.\n",
        "\n",
        "Train the Model: Train this model using the same parameters as the previous step (validation split of 0.2, 10 epochs). Remember to use the training data for training the model.\n",
        "\n",
        "Evaluate the Model: Evaluate your model on the test set and report the performance metrics.\n",
        "\n",
        "Analyze: Analyze if the designed models performance has improved as intended. Outline any strategies you used to improve the performance, and discuss the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1I9k_du7xDm"
      },
      "source": [
        "# Step 1:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urwvLZA44aYB",
        "outputId": "ea81b086-4a96-4897-e914-a331c5f6faf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1573376   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1738890 (6.63 MB)\n",
            "Trainable params: 1738890 (6.63 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8971 - accuracy: 0.3080 - val_loss: 1.7652 - val_accuracy: 0.3557\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7149 - accuracy: 0.3839 - val_loss: 1.7451 - val_accuracy: 0.3708\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.6332 - accuracy: 0.4157 - val_loss: 1.6386 - val_accuracy: 0.4140\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.5702 - accuracy: 0.4378 - val_loss: 1.6075 - val_accuracy: 0.4183\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.5334 - accuracy: 0.4494 - val_loss: 1.5940 - val_accuracy: 0.4325\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.4916 - accuracy: 0.4669 - val_loss: 1.5561 - val_accuracy: 0.4426\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.4669 - accuracy: 0.4747 - val_loss: 1.5556 - val_accuracy: 0.4436\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.4386 - accuracy: 0.4861 - val_loss: 1.5157 - val_accuracy: 0.4534\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.4139 - accuracy: 0.4988 - val_loss: 1.5190 - val_accuracy: 0.4571\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.3899 - accuracy: 0.5015 - val_loss: 1.4739 - val_accuracy: 0.4743\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 1.4639 - accuracy: 0.4791\n",
            "Test accuracy: 0.47909998893737793\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "import keras\n",
        "\n",
        "\n",
        "# First, build a simple neural network for the CIFAR-10 dataset. You will need to:\n",
        "# Load the CIFAR-10 dataset from Keras. Normalize the data and transform the labels to a categorical format. Define that simple neural network.\n",
        "# This network should have at least three hidden layer using 'relu' activation and a softmax output layer for the 10 classes of the CIFAR-10 dataset.\n",
        "# Compile the model. Use 'categorical_crossentropy' for your loss function and 'adam' as the optimizer. The metrics will be 'accuracy'. Train the model.\n",
        "# Use a validation split of 0.2. Train for 10 epochs. Evaluate the model on the test set and report its accuracy.\n",
        "\n",
        "# Load Data\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 10\n",
        "# ========== YOUR CODE STARTS HERE ==========\n",
        "y_train_full = keras.utils.to_categorical(y_train_full, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size = 0.2, random_state = 42)\n",
        "# ========== YOUR CODE ENDS HERE ==========\n",
        "\n",
        "\n",
        "# Define Network\n",
        "# ========== YOUR CODE STARTS HERE ==========\n",
        "model = Sequential([\n",
        "        Flatten(input_shape=(32, 32, 3)),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# ========== YOUR CODE ENDS HERE ==========\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile Model\n",
        "# ========== YOUR CODE ENDS HERE ==========\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# ========== YOUR CODE ENDS HERE ==========\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train Model\n",
        "# ========== YOUR CODE ENDS HERE ==========\n",
        "model.fit(x_train, y_train, epochs=10, validation_data = (x_val, y_val))\n",
        "# ========== YOUR CODE ENDS HERE ==========\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g16-s8aG74eI"
      },
      "source": [
        "# Step 2:\n",
        "\n",
        "## Your findings:\n",
        "\n",
        "The models with gelu and relu activation yielded the highest test accuracys at around 48%.\n",
        "\n",
        "The model with sigmoid activation had a test accuracy of 39% while the model with a tanh activation only had 30% accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boxe8Ce17_CP",
        "outputId": "c883f485-5d4a-43a6-a09a-85796b0bf132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               1573376   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1738890 (6.63 MB)\n",
            "Trainable params: 1738890 (6.63 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9669 - accuracy: 0.2733 - val_loss: 1.9041 - val_accuracy: 0.2982\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8314 - accuracy: 0.3327 - val_loss: 1.7751 - val_accuracy: 0.3536\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7772 - accuracy: 0.3539 - val_loss: 1.7350 - val_accuracy: 0.3676\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7375 - accuracy: 0.3685 - val_loss: 1.8066 - val_accuracy: 0.3575\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7138 - accuracy: 0.3774 - val_loss: 1.7403 - val_accuracy: 0.3628\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7021 - accuracy: 0.3785 - val_loss: 1.6949 - val_accuracy: 0.3708\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.6792 - accuracy: 0.3911 - val_loss: 1.6988 - val_accuracy: 0.3802\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.6597 - accuracy: 0.4011 - val_loss: 1.6708 - val_accuracy: 0.3902\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.6458 - accuracy: 0.4025 - val_loss: 1.6783 - val_accuracy: 0.3941\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 3s 3ms/step - loss: 1.6355 - accuracy: 0.4070 - val_loss: 1.6729 - val_accuracy: 0.3886\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 1.6547 - accuracy: 0.3913\n",
            "Test accuracy: 0.3912999927997589\n"
          ]
        }
      ],
      "source": [
        "# Next, experiment with different activation functions. Repeat the Step 1 process three times-- once with 'relu' replaced with 'sigmoid',\n",
        "# once with 'tanh', and finally with 'gelu'. For each, evaluate the model's performance and document any changes you observe.\n",
        "\n",
        "# Change activation function (sigmoid)\n",
        "model = Sequential([\n",
        "        Flatten(input_shape=(32, 32, 3)),\n",
        "        Dense(512, activation='sigmoid'),\n",
        "        Dense(256, activation='sigmoid'),\n",
        "        Dense(128, activation='sigmoid'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# Train the Model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNJIb1JrfeOS",
        "outputId": "7f131a3f-424b-40b2-cd28-85241e3fcfa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               1573376   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1738890 (6.63 MB)\n",
            "Trainable params: 1738890 (6.63 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 2.0687 - accuracy: 0.2166 - val_loss: 2.0288 - val_accuracy: 0.2185\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9958 - accuracy: 0.2526 - val_loss: 1.9419 - val_accuracy: 0.2708\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9695 - accuracy: 0.2697 - val_loss: 1.9401 - val_accuracy: 0.2872\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9498 - accuracy: 0.2829 - val_loss: 1.9237 - val_accuracy: 0.2924\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9408 - accuracy: 0.2863 - val_loss: 1.9382 - val_accuracy: 0.2856\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9247 - accuracy: 0.2954 - val_loss: 1.9063 - val_accuracy: 0.3074\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9073 - accuracy: 0.3000 - val_loss: 1.9217 - val_accuracy: 0.2791\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9049 - accuracy: 0.3006 - val_loss: 1.9346 - val_accuracy: 0.2911\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9016 - accuracy: 0.3022 - val_loss: 1.9261 - val_accuracy: 0.2890\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8961 - accuracy: 0.3076 - val_loss: 1.9142 - val_accuracy: 0.2957\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 1.9108 - accuracy: 0.3012\n",
            "Test accuracy: 0.3012000024318695\n"
          ]
        }
      ],
      "source": [
        "# Change activation function (tanh)\n",
        "model = Sequential([\n",
        "        Flatten(input_shape=(32, 32, 3)),\n",
        "        Dense(512, activation='tanh'),\n",
        "        Dense(256, activation='tanh'),\n",
        "        Dense(128, activation='tanh'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# Train the Model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg7ROkuBfd-w",
        "outputId": "8e5b8a34-8bf6-4271-affd-d8c27702ba33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               1573376   \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1738890 (6.63 MB)\n",
            "Trainable params: 1738890 (6.63 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8676 - accuracy: 0.3227 - val_loss: 1.7700 - val_accuracy: 0.3549\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6767 - accuracy: 0.3968 - val_loss: 1.6304 - val_accuracy: 0.4055\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5854 - accuracy: 0.4283 - val_loss: 1.5609 - val_accuracy: 0.4357\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5239 - accuracy: 0.4539 - val_loss: 1.5621 - val_accuracy: 0.4440\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4794 - accuracy: 0.4671 - val_loss: 1.5387 - val_accuracy: 0.4482\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4438 - accuracy: 0.4851 - val_loss: 1.4949 - val_accuracy: 0.4620\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4054 - accuracy: 0.4978 - val_loss: 1.4743 - val_accuracy: 0.4773\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3779 - accuracy: 0.5071 - val_loss: 1.5454 - val_accuracy: 0.4533\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3554 - accuracy: 0.5142 - val_loss: 1.4827 - val_accuracy: 0.4808\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3263 - accuracy: 0.5267 - val_loss: 1.4688 - val_accuracy: 0.4795\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 1.4539 - accuracy: 0.4817\n",
            "Test accuracy: 0.48170000314712524\n"
          ]
        }
      ],
      "source": [
        "# Change activation function (gelu)\n",
        "model = Sequential([\n",
        "        Flatten(input_shape=(32, 32, 3)),\n",
        "        Dense(512, activation='gelu'),\n",
        "        Dense(256, activation='gelu'),\n",
        "        Dense(128, activation='gelu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# Train the Model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWt1xCuE8fIP"
      },
      "source": [
        " # Step 3:\n",
        "\n",
        " ## Your findings:\n",
        " In step 3, I modified the number of parameters in each layer using the relu activation function, a softmax layer, the adam optimizer, and categorial_crossentorpy loss.\n",
        "\n",
        " From the results, it can be observed the the number of parameters do not change the accuracy of the model in this specific case. \n",
        " \n",
        " The first model with an initial hidden layer of 1024 actually performed worse than the model that only contained 256 neurons as their first layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4KULS418tMk",
        "outputId": "b1dc320f-f481-48df-ded3-4a35ba2def0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              3146752   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3805450 (14.52 MB)\n",
            "Trainable params: 3805450 (14.52 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.9027 - accuracy: 0.3104 - val_loss: 1.7343 - val_accuracy: 0.3776\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7082 - accuracy: 0.3858 - val_loss: 1.6664 - val_accuracy: 0.4063\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6213 - accuracy: 0.4203 - val_loss: 1.6509 - val_accuracy: 0.4123\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5629 - accuracy: 0.4372 - val_loss: 1.6160 - val_accuracy: 0.4215\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5185 - accuracy: 0.4532 - val_loss: 1.5370 - val_accuracy: 0.4478\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4855 - accuracy: 0.4676 - val_loss: 1.5255 - val_accuracy: 0.4529\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4543 - accuracy: 0.4787 - val_loss: 1.5616 - val_accuracy: 0.4454\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4277 - accuracy: 0.4865 - val_loss: 1.6199 - val_accuracy: 0.4202\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4036 - accuracy: 0.4956 - val_loss: 1.5266 - val_accuracy: 0.4555\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3803 - accuracy: 0.5054 - val_loss: 1.5467 - val_accuracy: 0.4524\n",
            "313/313 [==============================] - 0s 2ms/step - loss: 1.5251 - accuracy: 0.4647\n",
            "Test accuracy: 0.46470001339912415\n"
          ]
        }
      ],
      "source": [
        "# increase number of parameters in the network\n",
        "model = Sequential([\n",
        "        Flatten(input_shape=(32,32,3)),\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# Train the Model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVaXaKxCfTY8",
        "outputId": "1f3a0c57-1426-40af-ad6b-bda11830357c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               786688    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 828490 (3.16 MB)\n",
            "Trainable params: 828490 (3.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 2s 1ms/step - loss: 1.9156 - accuracy: 0.3044 - val_loss: 1.7877 - val_accuracy: 0.3545\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 2s 1ms/step - loss: 1.7257 - accuracy: 0.3789 - val_loss: 1.6638 - val_accuracy: 0.3995\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 2s 1ms/step - loss: 1.6396 - accuracy: 0.4152 - val_loss: 1.6612 - val_accuracy: 0.3979\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 2s 1ms/step - loss: 1.5867 - accuracy: 0.4323 - val_loss: 1.5610 - val_accuracy: 0.4416\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 2s 1ms/step - loss: 1.5481 - accuracy: 0.4466 - val_loss: 1.5727 - val_accuracy: 0.4316\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 2s 1ms/step - loss: 1.5157 - accuracy: 0.4615 - val_loss: 1.5361 - val_accuracy: 0.4497\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 2s 1ms/step - loss: 1.4900 - accuracy: 0.4672 - val_loss: 1.5273 - val_accuracy: 0.4565\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 2s 1ms/step - loss: 1.4647 - accuracy: 0.4749 - val_loss: 1.5066 - val_accuracy: 0.4545\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 2s 1ms/step - loss: 1.4432 - accuracy: 0.4854 - val_loss: 1.4994 - val_accuracy: 0.4677\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 2s 1ms/step - loss: 1.4222 - accuracy: 0.4949 - val_loss: 1.4905 - val_accuracy: 0.4641\n",
            "313/313 [==============================] - 0s 514us/step - loss: 1.4785 - accuracy: 0.4771\n",
            "Test accuracy: 0.4771000146865845\n"
          ]
        }
      ],
      "source": [
        "# Reduce number of parameters in the network\n",
        "\n",
        "model = Sequential([\n",
        "        Flatten(input_shape=(32, 32, 3)),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# Train the Model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikiG8r2w867A"
      },
      "source": [
        "# Step 4:\n",
        "\n",
        " ## Your findings and report the number of parameters as well (should be the same):\n",
        "\n",
        " In this step, I have one model with a wide layer of 512 neurons (1.57 million parameters) in a single hidden layer while the other model contains eight hidden layers of 303 neurons (1.57 million parameters).\n",
        "\n",
        " It can be observed from the test accuracy that the accuracy does not differ too much. There is roughly a one percent difference in accuracy between the two models. \n",
        "\n",
        " Therefore, it can be concluded that changing the shape of the network does not impact the accuracy of the model significantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI7IiwR38_Ie",
        "outputId": "bd9738c1-b159-4f4e-a545-17356100771f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1573376   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1578506 (6.02 MB)\n",
            "Trainable params: 1578506 (6.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 3s 2ms/step - loss: 1.9177 - accuracy: 0.3196 - val_loss: 1.7642 - val_accuracy: 0.3721\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 3s 2ms/step - loss: 1.7195 - accuracy: 0.3848 - val_loss: 1.6641 - val_accuracy: 0.4041\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 3s 2ms/step - loss: 1.6589 - accuracy: 0.4087 - val_loss: 1.6379 - val_accuracy: 0.4125\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 3s 2ms/step - loss: 1.6121 - accuracy: 0.4243 - val_loss: 1.6592 - val_accuracy: 0.3968\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 3s 2ms/step - loss: 1.5780 - accuracy: 0.4402 - val_loss: 1.5925 - val_accuracy: 0.4342\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 3s 2ms/step - loss: 1.5516 - accuracy: 0.4498 - val_loss: 1.5978 - val_accuracy: 0.4267\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 3s 2ms/step - loss: 1.5338 - accuracy: 0.4544 - val_loss: 1.5737 - val_accuracy: 0.4336\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 3s 2ms/step - loss: 1.5147 - accuracy: 0.4628 - val_loss: 1.5449 - val_accuracy: 0.4511\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 3s 2ms/step - loss: 1.5023 - accuracy: 0.4645 - val_loss: 1.5473 - val_accuracy: 0.4520\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 3s 2ms/step - loss: 1.4832 - accuracy: 0.4730 - val_loss: 1.5422 - val_accuracy: 0.4495\n",
            "313/313 [==============================] - 0s 983us/step - loss: 1.5276 - accuracy: 0.4598\n",
            "Test accuracy: 0.45980000495910645\n"
          ]
        }
      ],
      "source": [
        "# Increase width, decrease depth\n",
        "\n",
        "model = Sequential([\n",
        "        Flatten(input_shape=(32, 32, 3)),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# Train the Model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQmOtJBjfhis",
        "outputId": "89f4ee69-fa38-4f65-96b2-dce1cca11be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 351)               1078623   \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 351)               123552    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 351)               123552    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 351)               123552    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 351)               123552    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 10)                3520      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1576351 (6.01 MB)\n",
            "Trainable params: 1576351 (6.01 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9293 - accuracy: 0.2877 - val_loss: 1.7861 - val_accuracy: 0.3535\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7649 - accuracy: 0.3620 - val_loss: 1.7445 - val_accuracy: 0.3667\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6855 - accuracy: 0.3944 - val_loss: 1.7046 - val_accuracy: 0.3922\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6214 - accuracy: 0.4170 - val_loss: 1.6690 - val_accuracy: 0.4058\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5796 - accuracy: 0.4331 - val_loss: 1.6026 - val_accuracy: 0.4254\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5449 - accuracy: 0.4464 - val_loss: 1.5716 - val_accuracy: 0.4371\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5091 - accuracy: 0.4575 - val_loss: 1.5511 - val_accuracy: 0.4460\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4744 - accuracy: 0.4694 - val_loss: 1.5255 - val_accuracy: 0.4547\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4554 - accuracy: 0.4761 - val_loss: 1.5389 - val_accuracy: 0.4523\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4217 - accuracy: 0.4908 - val_loss: 1.5478 - val_accuracy: 0.4557\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 1.5272 - accuracy: 0.4690\n",
            "Test accuracy: 0.4690000116825104\n"
          ]
        }
      ],
      "source": [
        "# Increase depth, decrease width\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(32, 32, 3)),\n",
        "    Dense(351, activation='relu'),  \n",
        "    Dense(351, activation='relu'),  \n",
        "    Dense(351, activation='relu'),  \n",
        "    Dense(351, activation='relu'),  \n",
        "    Dense(351, activation='relu'),  \n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# Train the Model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99uzMJfH-TBT"
      },
      "source": [
        "# Step 5: Building an Optimized Neural Network\n",
        "\n",
        "\n",
        "## Discsuss:\n",
        "In this step, I attempted to put together the best traits of the models above. \n",
        "\n",
        "My model consists of five hidden layers with the gelu activation because that activation function yielded the highest accuracy earlier.\n",
        "\n",
        "Also, from what I observed in the previous step, it is beneficial to have multiple layers to process, hence the five hidden layers of 512 neurons each.\n",
        "\n",
        "I noticed that the model was doing better than the other ones during training, but had a mediocre performance on the test model. \n",
        "\n",
        "I believe that this is due to the high number of parameters in the model which may have led to overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwcJ10tx-Rth",
        "outputId": "fb954ac6-9799-44db-8179-f596600dc944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 512)               1573376   \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2629130 (10.03 MB)\n",
            "Trainable params: 2629130 (10.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 1.8984 - accuracy: 0.3037 - val_loss: 1.7632 - val_accuracy: 0.3555\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 1.7473 - accuracy: 0.3677 - val_loss: 1.7422 - val_accuracy: 0.3602\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.6619 - accuracy: 0.4022 - val_loss: 1.6540 - val_accuracy: 0.4146\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 1.6043 - accuracy: 0.4224 - val_loss: 1.6132 - val_accuracy: 0.4247\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 1.5580 - accuracy: 0.4393 - val_loss: 1.6711 - val_accuracy: 0.4016\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 1.5089 - accuracy: 0.4586 - val_loss: 1.6616 - val_accuracy: 0.4085\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 1.4721 - accuracy: 0.4701 - val_loss: 1.5630 - val_accuracy: 0.4422\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 1.4288 - accuracy: 0.4839 - val_loss: 1.5340 - val_accuracy: 0.4557\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 1.3919 - accuracy: 0.5002 - val_loss: 1.5211 - val_accuracy: 0.4584\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 1.3556 - accuracy: 0.5099 - val_loss: 1.5387 - val_accuracy: 0.4566\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5310 - accuracy: 0.4632\n",
            "Test accuracy: 0.46320000290870667\n"
          ]
        }
      ],
      "source": [
        "# Your network here\n",
        "\n",
        "model = Sequential([\n",
        "        Flatten(input_shape=(32, 32, 3)),\n",
        "        Dense(512, activation='gelu'),\n",
        "        Dense(512, activation='gelu'),\n",
        "        Dense(512, activation='gelu'),\n",
        "        Dense(512, activation='gelu'),\n",
        "        Dense(512, activation='gelu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# Train the Model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnwFDhEJ5p8R"
      },
      "source": [
        "# Part 2 CNN\n",
        "\n",
        "Utilizing the Keras Sequential model, define a Convolutional Neural Network (CNN) model that is adapted to classify images in the CIFAR-10 dataset. Add the necessary layers to the model.\n",
        "\n",
        "For example: * Convolutional layer * Pooling layer * Dropout layer * Flatten layer * Fully connected layer. Of course, you can use whatever you want.\n",
        "\n",
        "Make sure to select appropriate activation functions for the layers. Share your findings about CNN for image classification compared to the neural network of Part 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-FydRtR5p8R"
      },
      "source": [
        "## Your findings:\n",
        "In this step, I build a model from the suggested example above. The layers of this model include three convolutional layers, 2 pooling layers, and one fully connected layer at the end with a dropout of 0.5.\n",
        "\n",
        "This convolutional neural network yields a significantly higher training and test accuracy than all the other neural network models.\n",
        "\n",
        "I chose to use less parameters in the layers to prevent overfitting. It was also noticed earlier that having less parameters does not necessarily negatively affect the model.\n",
        "\n",
        "Therefore, it can be observed from the results that the CNN classifies images much more accurately than a regular CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AqQk988c5p8R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                65600     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122570 (478.79 KB)\n",
            "Trainable params: 122570 (478.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.7898 - accuracy: 0.3428 - val_loss: 1.4536 - val_accuracy: 0.4725\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4566 - accuracy: 0.4769 - val_loss: 1.2629 - val_accuracy: 0.5663\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 1.3065 - accuracy: 0.5332 - val_loss: 1.1354 - val_accuracy: 0.5965\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 1.2037 - accuracy: 0.5762 - val_loss: 1.1112 - val_accuracy: 0.6053\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1254 - accuracy: 0.6053 - val_loss: 1.0248 - val_accuracy: 0.6405\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 9s 8ms/step - loss: 1.0694 - accuracy: 0.6263 - val_loss: 0.9733 - val_accuracy: 0.6591\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0213 - accuracy: 0.6417 - val_loss: 0.9584 - val_accuracy: 0.6702\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.9781 - accuracy: 0.6566 - val_loss: 0.9151 - val_accuracy: 0.6856\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.9310 - accuracy: 0.6758 - val_loss: 0.9354 - val_accuracy: 0.6847\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.9046 - accuracy: 0.6828 - val_loss: 0.8935 - val_accuracy: 0.6896\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.9109 - accuracy: 0.6891\n",
            "Test Loss: 0.9109326004981995, Test Accuracy: 0.6891000270843506\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# # Load Data\n",
        "# (x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "# x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Model definition\n",
        "model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=x_train_full.shape[1:]),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# train the model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
